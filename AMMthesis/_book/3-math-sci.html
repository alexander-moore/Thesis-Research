<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 3 Neural Networks | Neural Network Methods in Complex Surveys</title>
  <meta name="description" content="Chapter 3 Neural Networks | Neural Network Methods in Complex Surveys">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 3 Neural Networks | Neural Network Methods in Complex Surveys" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Neural Networks | Neural Network Methods in Complex Surveys" />
  
  
  

<meta name="author" content="Alexander Michael Moore">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="2-complex-surveys.html">
<link rel="next" href="4-methods.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Delete line 6 if you only have one advisor</a></li>
<li class="chapter" data-level="2" data-path="2-complex-surveys.html"><a href="2-complex-surveys.html"><i class="fa fa-check"></i><b>2</b> Complex Surveys</a><ul>
<li class="chapter" data-level="2.1" data-path="2-complex-surveys.html"><a href="2-complex-surveys.html#survey-statistics"><i class="fa fa-check"></i><b>2.1</b> Survey Statistics</a></li>
<li class="chapter" data-level="2.2" data-path="2-complex-surveys.html"><a href="2-complex-surveys.html#imputation"><i class="fa fa-check"></i><b>2.2</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-math-sci.html"><a href="3-math-sci.html"><i class="fa fa-check"></i><b>3</b> Neural Networks</a><ul>
<li class="chapter" data-level="3.1" data-path="3-math-sci.html"><a href="3-math-sci.html#introduction-to-machine-learning"><i class="fa fa-check"></i><b>3.1</b> Introduction to Machine Learning</a></li>
<li class="chapter" data-level="3.2" data-path="3-math-sci.html"><a href="3-math-sci.html#neural-networks"><i class="fa fa-check"></i><b>3.2</b> Neural Networks</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-math-sci.html"><a href="3-math-sci.html#background-and-context"><i class="fa fa-check"></i><b>3.2.1</b> Background and Context</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-math-sci.html"><a href="3-math-sci.html#basics"><i class="fa fa-check"></i><b>3.2.2</b> Basics</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-math-sci.html"><a href="3-math-sci.html#representation-learning"><i class="fa fa-check"></i><b>3.2.3</b> Representation Learning</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-math-sci.html"><a href="3-math-sci.html#neural-networks-for-complex-survey-data"><i class="fa fa-check"></i><b>3.2.4</b> Neural Networks for Complex Survey Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-methods.html"><a href="4-methods.html"><i class="fa fa-check"></i><b>4</b> Methods</a><ul>
<li class="chapter" data-level="4.0.1" data-path="4-methods.html"><a href="4-methods.html#drop.na"><i class="fa fa-check"></i><b>4.0.1</b> Drop.NA</a></li>
<li class="chapter" data-level="4.1" data-path="4-methods.html"><a href="4-methods.html#mean-estimation-methods"><i class="fa fa-check"></i><b>4.1</b> Mean Estimation Methods</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-methods.html"><a href="4-methods.html#median-imputation"><i class="fa fa-check"></i><b>4.1.1</b> Median Imputation</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-methods.html"><a href="4-methods.html#linear-regression-imputation-weighted-pi"><i class="fa fa-check"></i><b>4.1.2</b> Linear Regression Imputation (weighted pi)</a></li>
<li class="chapter" data-level="4.1.3" data-path="4-methods.html"><a href="4-methods.html#naive-neural-network-imputation"><i class="fa fa-check"></i><b>4.1.3</b> Naive Neural Network Imputation</a></li>
<li class="chapter" data-level="4.1.4" data-path="4-methods.html"><a href="4-methods.html#loss-weighted-neural-network-imputation"><i class="fa fa-check"></i><b>4.1.4</b> Loss-Weighted Neural Network Imputation</a></li>
<li class="chapter" data-level="4.1.5" data-path="4-methods.html"><a href="4-methods.html#pi-feature-neural-network-imputation"><i class="fa fa-check"></i><b>4.1.5</b> <span class="math inline">\(\pi\)</span>-Feature Neural Network Imputation</a></li>
<li class="chapter" data-level="4.1.6" data-path="4-methods.html"><a href="4-methods.html#weighted-resample-neural-network-imputation"><i class="fa fa-check"></i><b>4.1.6</b> Weighted Resample Neural Network Imputation</a></li>
<li class="chapter" data-level="4.1.7" data-path="4-methods.html"><a href="4-methods.html#derived-feature-neural-network-imputation"><i class="fa fa-check"></i><b>4.1.7</b> Derived Feature Neural Network Imputation</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-methods.html"><a href="4-methods.html#tables"><i class="fa fa-check"></i><b>4.2</b> Tables</a></li>
<li class="chapter" data-level="4.3" data-path="4-methods.html"><a href="4-methods.html#bibliographies"><i class="fa fa-check"></i><b>4.3</b> Bibliographies</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a><ul>
<li class="chapter" data-level="4.4" data-path="conclusion.html"><a href="conclusion.html#future-work"><i class="fa fa-check"></i><b>4.4</b> Future Work</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-the-first-appendix.html"><a href="A-the-first-appendix.html"><i class="fa fa-check"></i><b>A</b> The First Appendix</a></li>
<li class="chapter" data-level="B" data-path="B-the-second-appendix-for-fun.html"><a href="B-the-second-appendix-for-fun.html"><i class="fa fa-check"></i><b>B</b> The Second Appendix, for Fun</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Neural Network Methods in Complex Surveys</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="math-sci" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Neural Networks</h1>
<!-- Required to number equations in HTML files -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<div id="introduction-to-machine-learning" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction to Machine Learning</h2>
<p>From the advent of computation, there has been drive towards automation.</p>
<p>The capacity to derive patterns from raw data is known as machine learning, a broad term for an extremely diverse collection of algorithms. Machine learning flips the script on classical programming: whereas classical programming takes rules and data to produce answers, machine learning creates rules from data and answers by being “trained rather than explicitly programmed. It’s presented with many examples relevant to a task, and it finds a structure that derives rules for automating the task” <span class="citation">(Chollet &amp; Allaire, 2018)</span>.</p>
<p>Machine learning is intended to elucidate or predict patterns in data. These algorithms handle anything from linear regression for predicting a numerical response based on a number of predictors, to clustering for visualization and assignment of untaught observation classes. The models are trained by minimizing error during exposure to labelled training data with some underlying distribution and random noise, then passed unlabelled test data to predict the corresponding unknown class or value. Predictive (or supervised) machine learning algorithms seek to emulate and elucidate a true unknown generative function from which the data were drawn.</p>
<p>For imputation purposes, our goal will be to accurately estimate missing values by approximating the generative function from which they are drawn. Generative functions have the following form <span class="math display">\[
y = f(x_1, x_2, .) + \epsilon
\]</span> Where the true label <span class="math inline">\(y\)</span> of the observation is a function of the features <span class="math inline">\(x_1, ..., x_n\)</span> perturbed by some random noise <span class="math inline">\(\epsilon\)</span>.</p>
<p>The estimating model will be trained via exposure to labelled observations, called the training data, then used to predict observations with missing labels, called testing data. The challenge in machine learning is learning the correct amount from training data, in order to derive the underlying distribution of the observations without simply memorizing the labels of the training set. This problem is called overfitting and is central to machine learning.</p>
<p><a href="3-math-sci.html#fig:overfit">3.1</a> is an illustration of this pervasive principle in a regression example. An overfit (or too-flexible) model simply learns the observation’s labels, rather than the underlying distribution (or generative function, in this case a second-degree polynomial). The overfit model fails to learn the underlying generative function, and instead learns the random noise of the training observations, and thus is a poor explanation of a new realization from the same generative function, seen in <a href="3-math-sci.html#fig:overfitre">3.2</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:overfit"></span>
<img src="figure/overfit.png" alt="The overfit model has extremely low error on the realization of the data on which it was trained."  />
<p class="caption">
Figure 3.1: The overfit model has extremely low error on the realization of the data on which it was trained.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:overfitre"></span>
<img src="figure/badfit.png" alt="However, the overfit model does not accurately reflect the underlying distribution from which both datasets are drawn. Rather, it captures only the random noise of the data on which it was trained. It would be a mistake to assume the generative function is a degree 15 polynomial just because the training error of such an approximation is low."  />
<p class="caption">
Figure 3.2: However, the overfit model does not accurately reflect the underlying distribution from which both datasets are drawn. Rather, it captures only the random noise of the data on which it was trained. It would be a mistake to assume the generative function is a degree 15 polynomial just because the training error of such an approximation is low.
</p>
</div>
<p>An underfit model <a href="3-math-sci.html#fig:underfit">3.3</a> also fails to capture the underlying distribution, due to a lack of flexibility. A linear regression, though it attempts to minimize its training MSE, clearly fails to capture the underlying distribution of the data:</p>
<div class="figure" style="text-align: center"><span id="fig:underfit"></span>
<img src="figure/underfit.png" alt="An underfit model fails to capture the underlying distribution"  />
<p class="caption">
Figure 3.3: An underfit model fails to capture the underlying distribution
</p>
</div>
<p><a href="3-math-sci.html#fig:underfit">3.3</a> A well-trained model which straddles these extrema captures the apparent underlying distribution of the data in a general sense by approximation the generative function from which they are drawn, and remains fairly constant under different draws from the same distribution:</p>
<div class="figure" style="text-align: center"><span id="fig:goodmod"></span>
<img src="figure/true.png" alt="This model has the correct level of flexibility, and accurately captures the underlying generative function while avoiding overtraining based on noise. This property gives it superior generalizability to new realizations of the data, which it was not trained on."  />
<p class="caption">
Figure 3.4: This model has the correct level of flexibility, and accurately captures the underlying generative function while avoiding overtraining based on noise. This property gives it superior generalizability to new realizations of the data, which it was not trained on.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:goodmod"></span>
<img src="figure/stayGood.png" alt="This model has the correct level of flexibility, and accurately captures the underlying generative function while avoiding overtraining based on noise. This property gives it superior generalizability to new realizations of the data, which it was not trained on."  />
<p class="caption">
Figure 3.4: This model has the correct level of flexibility, and accurately captures the underlying generative function while avoiding overtraining based on noise. This property gives it superior generalizability to new realizations of the data, which it was not trained on.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:biasvar"></span>
<img src="figure/biasvariance.png" alt="http://scott.fortmann-roe.com/docs/BiasVariance.html"  />
<p class="caption">
Figure 3.5: <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" class="uri">http://scott.fortmann-roe.com/docs/BiasVariance.html</a>
</p>
</div>
<p><a href="3-math-sci.html#fig:biasvar">3.5</a> demonstrates the involvement of model complexity (or flexibility) in terms of training error. Model complexity refers to the ability of the model to approximate complex generative functions. We see that as the flexibility of the model increases, the bias on the training set always decreases, representing the model’s performance on observations with labels. However,complexity beyond the models optimal value implies over-flexibility, in which the model is able to memorize random noise rather than stopping at the trend of the data. This increases the total error if the model when exposed to data that comes from the same generative function that the model has not been exposed to, such as a testing data set or another observation from outside the training set. Higher flexibility models create more variable models, which though trained on data from the same generative function, differ greatly in appearance due to the random sample taken from the population which makes our training data, and are unstable for inference and generalizable predictivity.</p>
<p>One key difference from statistical modelling and survey statistics methods is the point at which randomness is introduced into the data. Machine learning attempts to approximate the function from which the data was randomly generated, while survey statistics imply that randomness in data comes from the survey design. The paradox of where randomness is introduced into the data is resolved with the existence of a superpopulation <span class="math inline">\(U\)</span>, where each observation has label <span class="math inline">\(y = f(x) + \epsilon\)</span>, some generative function. From this superpopulation, a population <span class="math inline">\(u\)</span> is created through <em>i.i.d.</em> realizations from <span class="math inline">\(U\)</span>. From this population <span class="math inline">\(u\)</span>, the survey is taken. Thus there still exists a generative function from which the population is drawn, but the features and label of the observations are fixed by the time the complex survey is taken on the population, reconciling the two methodologies.</p>
</div>
<div id="neural-networks" class="section level2">
<h2><span class="header-section-number">3.2</span> Neural Networks</h2>
<div id="background-and-context" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Background and Context</h3>
<p>Neural networks are a family of machine learning algorithms with an extended and diverse history of research in neuroscience, statistics, and computer science. Recently, these models have experienced great growth in attention and popularity due to the contemporary circumstance of great strides in computational capability. Neural networks thrives on large training data sets, which have trended to increase in size and availability throughout time, and alongside data sets with huge amounts of observations and predictors are more sophisticated deep learning models. Neural networks also outperform competing algorithms in high-dimensional feature problems, which are common in real-world machine learning applications such as image data, waveform data, and large surveys. Often utilizing derivatives of complex compositions of functions as an optimization method, deep learning training periods are computationally intensive, relying heavily on computer hardware and optimized software for reasonable implementation. Lastly, recent attention to and development of neural networks can be attributed to their proven potential in solving complicated real-world applications with promising and increasingly dominant accuracy in practice, often at the cost of a lack of inferability.</p>
<p>This lack of infer-ability is the typical downside of working with neural networks as the inference on a model can be more important than the predictive accuracy depending on the problem. Once a simple linear regression is trained, the coefficients on the predictors offer an immediately understandable interpretation of the behavior of the data. For example, a coefficient of .3 on a predictor <span class="math inline">\(x\)</span> has a simple, instant understanding: as predictor <span class="math inline">\(x\)</span> goes up by 1, the response goes up by .3. Neural networks however, lack this instant recognition due to the less intuitive layered structure of input transformations, known as representation learning.</p>
</div>
<div id="basics" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Basics</h3>
<p>Neural Networks are a composition of functions. The following describes a full neural network:</p>
<p><span class="math display">\[
\hat y = f(x; \theta, \omega) = f^n ( f^{n-1}  ( . f^1(x)))
\]</span> In this function, we see the input features <span class="math inline">\(x\)</span>, the learned coefficients <span class="math inline">\(\theta\)</span>, the learning rate <span class="math inline">\(\omega\)</span>, and the output prediction <span class="math inline">\(\hat{y}\)</span>. Consider one of the layers of the network, <span class="math inline">\(f_i\)</span>. This layer is an activation function on linear function:</p>
<p><span class="math display">\[
f^i = \max ( 0 , {W_i}^T x + c_i)
\]</span></p>
<p>The activation function shown above is the rectified linear unit, or <span class="math inline">\(\max(0,a)\)</span>. Activation functions are significant as they introduce nonlinearity into what would otherwise be a linear function (a composition of linear functions). <span class="math inline">\({W_i}^T\)</span> and <span class="math inline">\(c\)</span> in <span class="math inline">\(f_i\)</span> dictate a linear transformation on the input to the layer an ordered list of all elements of <span class="math inline">\(W_i\)</span> and <span class="math inline">\(c_i\)</span> for all <span class="math inline">\(i \in n\)</span> would give the full description of the network, called <span class="math inline">\(\theta\)</span>. So the output of a 1-layer network can be expressed as</p>
<p><span class="math display">\[
f(x; W, c, w, b) = w^T \max( 0 , W^T x +c ) +b
\]</span></p>
<pre><code>The final activation function is another structural parameter left to the designer of the network. The typical choices are</code></pre>
<ul>
<li>Linear units for Gaussian output distributions</li>
<li>Sigmoid units for Bernoulli output distributions</li>
<li>Softmax units for Multinoulli output distributions <span class="citation">(Goodfellow, Bengio, &amp; Courville, 2016)</span></li>
</ul>
<p>The learning rate <span class="math inline">\(\omega\)</span> and a cost function are meta-parameters, given by the user creating the neural network. These two parameters are used during the training of the network. During training, gradient descent is used to descend the cost function in order to find the optimal parameters for the network.</p>
<div class="figure" style="text-align: center"><span id="fig:optimize"></span>
<img src="figure/optimize.png" alt="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471"  />
<p class="caption">
Figure 3.6: <a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" class="uri">https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471</a>
</p>
</div>
<p>Can improve this image and example, but the lesson is good.</p>
<p>Figure <a href="3-math-sci.html#fig:optimize">3.6</a></p>
<p>We can see that the loss, perhaps MSE for an example, is a function of <span class="math inline">\(m\)</span> and <span class="math inline">\(c\)</span> which is minimized at <span class="math inline">\(m = 0\)</span> and <span class="math inline">\(c = 0\)</span>. The learning rate is the amount the functions coefficients are updated as the cost function is optimized using gradient descent.</p>
<p>The training of the neural network aims to drive the approximating function to the underlying function. This is done with gradient learning using a loss function, or maximum likelihood estimation. Most modern neural networks are trained using maximum likelihood, in which the cost function is the negative log-likelihood between the training data and model distribution <span class="citation">(Goodfellow et al., 2016)</span>.</p>
<p>Loss functions are ways of describing performance of a model on predicting labels of a data set. The loss function takes the model and data as inputs, and outputs a real number. Loss functions can be descended in training by optimization to lead the network to find improvements in weights leading to more accurate predictions. Loss functions allow for another degree of customization in the training of a network, such as in Ridge and LASSO regression. These algorithms add a weighting to the typical mean squared error loss function which penalizes the weights on predictors in polynomial regression. These methods introduce bias into otherwise unbiased algorithms, but reduce the variability of the model across different draws of data from the same distribution, aiming to reduce the real test loss and improve the model. The cross entropy between the data distribution and the model distribution is the typical choice <span class="citation">(Goodfellow et al., 2016)</span>.</p>
<p>Cross Entropy: <span class="math display">\[
\int_\chi P(x) \log Q (x) dr(x) = E_p [- \log Q]
\]</span></p>
<p>Take for example the Mean Squared Error cost function: <span class="math display">\[
MSE = \frac{1}{n} \sum_{k=1}^n  (y - \hat y)
\]</span></p>
<p>MSE, a typical loss function for regression applications, takes the mean squared difference of the predicted label <span class="math inline">\(\hat y\)</span> and the true label <span class="math inline">\(y\)</span> of the observations.</p>
<p>Successive layers of the network learn representation transformations of the data which lend themselves to increasingly accurate description by linear regression and activation performed by the final layer, called the output layer. This process of successive transformation learns meaningful representations on which the output layer can be most accurate. Since the full network does not have a single functional representation, it is nonparametric. The flexibility and power of neural networks in fields demanding domain knowledge is that they can approximate any function, per the Universal Approximation Theorem (Hornik et al., 1989; Cybenko, 1989), which states that a feedforward network with a linear output layer and at least one hidden layer with any “squashing” activation function (such as the logistic sigmoid activation function) can approximate any Borel measurable function from one finite-dimensional space to another with any desired nonzero amount of error, provided that the network is given enough hidden units. Thus the only user decision required would be the structure of the network, solvable through validation set meta-analysis.</p>
</div>
<div id="representation-learning" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Representation Learning</h3>
<p>If you were handed a photograph and were asked if it contained car, there’s a good chance you would immediately know the answer. But how are you coming to this conclusion? The human mind recognizes patterns of the image it has seen before, like a round bumper, a rectangular windshield, and a few circular tires with a certain spatial relationship to come to the conclusion that there is, in fact, a car in the photograph. It is this process of representation learning that prompted early researchers [[Citation Needed]] to create representation-based learning algorithms to extrapolate on information in the same way as the human mind. The emulation of human neural cells was the birth of deep learning, a class of machine learning algorithms which takes its name from multiple layers of connected nodes simulating a proposed structure of the neurons of the human mind. Representation learning takes observation’s features as a first layer into a composition of functions, in which each layer (or function) transforms the data according to a learned representation transformation that the subsequent layer takes as an input. This composition allows for complex relationships of features to be learned in increasingly sophisticated ways, making neural networks ideal for large-dimensional datasets with complex predictor relationships. For large-dimensional features, such as in Consumer Spending Data, images, or audio, these hierarchical representations (or layered representations) are important for distilling human-like feature extraction and iterative predictor space transformation. To achieve hierarchical representation properties, subsequent layers understand more complex functions of input variables as each layer transforms inputs and optimizes weights and weight relationships that minimize the overall loss of the network. As each layer receives the transformed output of the previous layer, more complex relationships of features can be derived.</p>
<p>Representation learning is extremely important to the broad promises of neural networks in practice. The basis for this strength is that subsequent layers of the network learn meaningful structures of the input data associated with a lower loss score. Correlations of predictors forming a functional relationship of features to output which induce loss function descent will be internalized by the composition of subsequent functions. This property of representation learning is significant for investigating the necessity of independent and identically distributed data in deep learning algorithms, as it could be the case that significance of the inclusion probability can be learned as a meaningful predictor, with no special tweaks or preprocessing necessary for the algorithm. No special tweeks required is extremely meaningful as it circumvents the necessity of incorporating domain knowledge and expertise in current imputation methods, which holds back expedient and lightweight research.</p>
<p>These advantages of Hierarchical and Distributed Representation transformation give neural networks huge advantages in accuracy and fitting capability for data with a massive hypothesis space. A hypothesis space is the space of all possible answers to a question. Image classification, for instance, represents a hypothesis space of pixels with unknown correlations that must be trained with label relationships to determine the correct distillation of millions of pixels to a most-likely class label. Thus the curse of dimensionality common throughout machine learning is mitigated through this manifold learning process.</p>
<p>Neural networks thrive in the interaction of many predictors, due to the nature of representation learning which excels in covariate relations and distilling information encoded between many features. Popular modern applications are image and waveform audio data, in which machine learning problems become dominated by the Curse of Dimensionality. This common machine learning problem arises when the amount of data is insignificant when compared to the hypothesis space or feature space, and there are sparse observations for some regions. Machine learning needs many observations with each combination of values, but this becomes quickly infeasible for data with thousands of features. The peaking phenomena dictates that there is an optimal number of features to describe the data before the curse of dimensionality creates problematic sparsity and dominating observations with few neighbors . Neural networks are known to resist this commonplace issue due to the distributed learning property, wherein each node is sensitive to only particular features.</p>
<p>Distributed representation is a powerful implicit component of neural networks in which neurons divide feature space to better handle feature interactions: suppose an image-recognition system could recognize cars, trucks, and birds, as well as distinguish if these objects are red, green, or blue. One way of representing these inputs could be to have a separate neuron for each combination: red truck, red car, red bird, and so on for nine independent neurons. Distributed representation, however, could partition these workloads by having three neurons for color and three for object type. In addition to reducing the number of neurons required dimensionally, this also distributes the learning demands of each neuron. The neuron describing redness is able to learn about redness from any category, not one specific category as the red bird neuron must <span class="citation">(Goodfellow et al., 2016)</span>.</p>
<p>Neural networks approximate nonlinear functions by applying linear models not to the features x, but to a transformed input, <span class="math inline">\(\phi(x)\)</span>, where <span class="math inline">\(\phi\)</span> is a nonlinear transformation. <span class="math inline">\(\phi\)</span> provides a new, more meaningful representation for <span class="math inline">\(x\)</span>. The question then is how to choose the mapping <span class="math inline">\(\phi\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>One option is to manually engineer <span class="math inline">\(\phi\)</span>. This takes a huge speciality of domain knowledge and practitioner specialization, with little transfer between domains. This was the dominant method before deep learning <span class="citation">(Goodfellow et al., 2016)</span>.</p></li>
<li><p>The strategy of neural networks comes from the learning of <span class="math inline">\(\phi\)</span>. “In this approach, we have a model y = f(x; theta, w) as specified in the neural network introduction. Due to the Universal Approximation Theorem, the nonparametric deep feedforward network can learn a functional approximation from the input to the desired output. This method sacrifices the training convexity of the other two, but benefits from the genericity of the specifications. The human user need only specify a general function family rather than exactly the correct function, but can still benefit from designing families of <span class="math inline">\(\phi(x; \theta)\)</span> that they expect to be relevant <span class="citation">(Goodfellow et al., 2016)</span>.</p></li>
</ol>
<p>The neural network approximates some true underlying function <span class="math inline">\(f^*(p; \theta)\)</span> of the predictors <span class="math inline">\(x\)</span> to the output category, <span class="math inline">\(y\)</span>, and learns the coefficients <span class="math inline">\(\theta\)</span> of the series of linear transformations composing the layers that result in the best function approximation. The number of functions in the composition is the called the depth of the model. Our model is called <span class="math inline">\(\hat f\)</span>, the generative function it seeks to approximate is called <span class="math inline">\(f\)</span>. The outputs of our model are <span class="math inline">\(\hat y\)</span> “guess at y” and the true labels are <span class="math inline">\(y\)</span>.</p>
</div>
<div id="neural-networks-for-complex-survey-data" class="section level3">
<h3><span class="header-section-number">3.2.4</span> Neural Networks for Complex Survey Data</h3>
<p>From an optimists’ perspective, the need for data preprocessing or special conditions on the loss function training the model would be unnecessary: If learning the correlations and underlying distributions associated with rare observations from complex survey design would truly lower the network’s loss, it should be learned and accounted for without need to perform special external transformations on the data to “undo” the effects of complex sample design. For this reason, it is significant to compare the potentially superior results of a naive model to one with superfluous data transformations done. A neural network model with access to an informative <span class="math inline">\(\pi\)</span> feature ideally would approximate the function relating the inclusion probability and features to labels, without the need for extreme domain knowledge and manual feature engineering.</p>
<p>Neural networks are extremely promising algorithms in supervised learning, and the weakness of inferability is not a problem for imputation tasks. The nonparametric nature of neural networks means that little domain knowledge is required, and no feature engineering is required, to have a neural network make meaningful label predictions using feature relationships.</p>
<ul>
<li><p>Nonparametric (circumvent domain knowledge) (per universal approximation thm)</p></li>
<li><p>Resist curse of dimensionality (that other parametrics and nonparametrics are exposed to)</p></li>
</ul>
<p>Have this be mentioned at the end of chapter 2 and explored w/ notation as chapter 3 Our goal is to diagnose potential bias incurred when ignoring complex survey design on data during the usage of deep neural networks. We have three algorithm tweaks for accommodating the influence of complex survey design.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-complex-surveys.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
