p_tbl <- as.tibble(p_df)
library(tidyverse)
# Chapter 4: Simulation
## Exploration of Methods in Simulation
Simulated data is used to evaluate the methods in order to get an understanding of their performance on a data set with known characteristics.
Full insight into the feature distributions, generative function, random noise, and systematic missingness allow for controlled experimentation on when certain methods thrive.
## High-Dimension Simulation
- noisy parameters
- higher dimension (for size of data)
@hastie2017extended
Often in real-world data, there might be a large number of features, not all of which are necessarily correlated to the response label. For example in the Consumer Expenditure data age, gender, ethnicity, and education might have a predictive relationship with income, while a number of others such as XXXXXXX do not. The ability for a model to discern which features are relevant and which are not is a significant benefit both for inference and predictive consistency. {@hastie2017extended}
These additional "noisy" parameters are approximated in simulated data by making the generative function of the labels $y$ not a function of a number of the features. All methods used in the simulation are accompanied by their "oracle" counterparts, meaning the same method is run two times: one with access to all features, the oracle restricted only to the relevant features which are inputs to the generative function.
## Monte Carlo Simulation
Monte Carlo (MC) simulation attempts to overcome the inherent randomness of sampling and neural network training by repeated iterations of the sampling, training, and evaluation steps. A distribution of evaluations is made over many possible samples from the population to get a more complete interpretation of the results.
It should be noted that neural networks can be more optimized than their performance in MC simulation. This is because a network can be intentionally over-trained on the training data, then re-trained from scratch to the number of epohcs which minimized the validation loss. This poses a challenge in MC simulation, however, where many iterations without user input are needed. Additionally, runtime becomes a vastly greater concern when networks must be over-trained through many epochs.
## Creating a Simulated Population
```{r sim_population, echo = TRUE, warning = FALSE, cache = TRUE}
library(tidyverse)
rescale <- function(vec) { # rescale to 0,1
(vec - min(vec)) / (max(vec) - min(vec))
}
N = 10^5
n = 10^3
it <- 100
p_y_ep_control <- 1
p_1 <- runif(N, -30, 30)
p_2 <- runif(N, -30, 30)
nulls <- matrix(rnorm(20*N, 0, 8), ncol = 20)
p_y_ep <- rnorm(N, mean = 0, sd = p_y_ep_control)
p_y <- p_1^2 + p_2^2
p_y[p_y > mean(p_y)] <- mean(p_y)
p_y <- p_y + p_y_ep
p_y <- abs(p_y)
p_pi_ep <- rnorm(N, mean = 0, sd = 1)
temp_pi <- sqrt(p_y) + p_pi_ep
temp_pi <- rescale(temp_pi)
p_pi <- temp_pi * (n / sum(temp_pi))
p_df <- cbind(p_1, p_2, p_y, p_pi, nulls)
p_tbl <- as.tibble(p_df)
# Statistic_tracker stores the mean estimates of the sample for each method
statistic_tracker <- data.frame(true_mean = numeric(it),
oracle_mean = numeric(it),
pi_naive_mean = numeric(it),
median_imp_mean = numeric(it),
lin_imp_mean = numeric(it),
lin_oracle = numeric(it),
nn_imp_mean = numeric(it),
nn_oracle = numeric(it),
nn_pi_imp_mean = numeric(it),
nn_pi_oracle = numeric(it),
nn_resamp_imp_mean = numeric(it),
nn_resamp_oracle = numeric(it),
nn_wmse_imp_mean = numeric(it),
nn_wmse_oracle = numeric(it),
nn_deriv_imp_mean = numeric(it),
nn_deriv_oracle = numeric(it))
```
## Monte Carlo Method
I'm thinking that the code for all the methods can be in the back of the thesis in some kind of index.
```{r monte_carlo, echo = TRUE, warning = FALSE, cache=TRUE}
for (i in 1:it) {
sample_population_by_pi <- sample_n(tbl = p_tbl, size = n, replace = FALSE, weight = p_pi)
df <- sample_population_by_pi %>% rename(x_1 = p_1, #Since we are not dealing with population p_ anymore
x_2 = p_2,
pi = p_pi,
y = p_y)
# True mean
statistic_tracker$true_mean <- true_mean(df)
# Oracle mean estimate
statistic_tracker$oracle_mean <- oracle_mean(df)
# Systematic bias is introduced
indices <- sample(1:nrow(df), .2*nrow(df), prob = df$y)
dropped_obs <- df[indices,]
reduced_df <- df[-indices,]
# Oracle data set is made by removing uncorrelated features
odf <- df[,1:4]
o_dropped_obs <- odf[indices,]
o_reduced_df <- odf[-indices,]
}
```
##
for (i in 1:it) {
sample_population_by_pi <- sample_n(tbl = p_tbl, size = n, replace = FALSE, weight = p_pi)
df <- sample_population_by_pi %>% rename(x_1 = p_1, #Since we are not dealing with population p_ anymore
x_2 = p_2,
pi = p_pi,
y = p_y)
# True mean
statistic_tracker$true_mean <- true_mean(df)
# Oracle mean estimate
statistic_tracker$oracle_mean <- oracle_mean(df)
# Systematic bias is introduced
indices <- sample(1:nrow(df), .2*nrow(df), prob = df$y)
dropped_obs <- df[indices,]
reduced_df <- df[-indices,]
# Oracle data set is made by removing uncorrelated features
odf <- df[,1:4]
o_dropped_obs <- odf[indices,]
o_reduced_df <- odf[-indices,]
}
sample_population_by_pi <- sample_n(tbl = p_tbl, size = n, replace = FALSE, weight = p_pi)
df <- sample_population_by_pi %>% rename(x_1 = p_1, #Since we are not dealing with population p_ anymore
x_2 = p_2,
pi = p_pi,
y = p_y)
# True mean
statistic_tracker$true_mean <- true_mean(df)
# Oracle mean estimate
statistic_tracker$oracle_mean <- oracle_mean(df)
dropped_obs <- df[indices,]
reduced_df <- df[-indices,]
# Oracle data set is made by removing uncorrelated features
odf <- df[,1:4]
o_reduced_df <- odf[-indices,]
knitr::include_graphics("C:/Users/Alexander/Documents/Thesis Data/Thesis Writing Rmd/AMMthesis/figure/bowl.jpg")
knittr::include_graphics("C:\Users\Alexander\Documents\Thesis Data\Thesis Writing Rmd\AMMthesis\figure\network.png")
dat <- read.csv("c:/Users/Alexander/Documents/thesis stat tracker/model_selection2_5.csv")
dat <- dat[,-1]
dat
mse_table <- dat[1,]
for (i in 1:dim(dat)[2]) {
matdat <- as.matrix(dat)
mse_table[i] <- mean( (matdat[,i] - matdat[,1])^2 )
}
mse_table
oracle_ratio_table <- dat[1,]
for (i in 1:dim(dat)[2]) {
oracle_ratio_table[i] <- mse_table[i] / mse_table[2]
}
oracle_ratio_table
prb_table <- dat[1,]
mu_y <- mean(dat[,1])
for (i in 1:dim(dat)[2]) {
prb_table[i] <- 100 * ((mean(dat[,i]) - mu_y) / mu_y)
}
prb_table
library(kableExtra)
library(knitr)
mse_t <- transpose(mse_table)
oracle_t <- transpose(oracle_ratio_table)
prb_t <- transpose(prb_table)
binded <- cbind(mse_t, oracle_t, prb_t)
colnames(binded) <- c("MSE", "Oracle Ratio", "Relative Bias")
rownames(binded) <- colnames(statistic_tracker)
test <- binded
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
mse_t <- transpose(mse_table)
prb_t <- transpose(prb_table)
oracle_t <- transpose(oracle_ratio_table)
binded <- cbind(mse_t, oracle_t, prb_t)
colnames(binded) <- c("MSE", "Oracle Ratio", "Relative Bias")
rownames(binded) <- colnames(statistic_tracker)
binded
dim(binded)
dim(statistic_tracker
dim(statistic_tracker)
dim(statistic_tracker)
dim(colnames(statistic_tracker))
length(colnames(statistic_tracker))
binded <- as.data.frame(binded)
binded
rownames(binded) <- colnames(statistic_tracker)
dim(binded)
mse_t
mse_t <- transpose(mse_table)
oracle_t <- transpose(oracle_ratio_table)
prb_t <- transpose(prb_table)
binded <- cbind(mse_t, oracle_t, prb_t)
colnames(binded) <- c("MSE", "Oracle Ratio", "Relative Bias")
test <- binded
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
mse_t
mse_t <- transpose(as.numeric(mse_table))
mse_t <- transpose(mse_table)
mse_t
mse_table
bound <- rbind(mse_table, oracle_ratio_table, prb_table)
bound
rownames(bound) <- c("MSE", "Oracle Ratio", "Relative Bias")
test <- bound
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
?knitr
test <- transpose(bound)
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
bound
bound <- rbind(mse_table, oracle_ratio_table, prb_table)
rownames(bound) <- c("MSE", "Oracle Ratio", "Relative Bias")
test <- transpose(bound)
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
names(bound)
rownames(bound)
colnames(bound)
test
rownames(test)
colnames(test)
dim(test)
t_bound <- transpose(bound)
# get row and colnames in order
colnames(t_bound) <- rownames(bound)
rownames(t_bound) <- colnames(bound)
library(data.table)
t_bound <- transpose(bound)
# get row and colnames in order
colnames(t_bound) <- rownames(bound)
rownames(t_bound) <- colnames(bound)
t_bound
test <- t_bound
test <- signif(test, digits = 3)
test %>%
kable() %>%
kable_styling()
